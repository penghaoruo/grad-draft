% This is paper draft for ECML
% the LaTeX2e class from Springer-Verlag
% for Lecture Notes in Computer Science, version 2.4
% edited by Haoruo Peng
\documentclass{llncs}
\usepackage{llncsdoc}
\usepackage{amsmath, amssymb}
\usepackage{color}
\usepackage{graphicx}

\newcommand{\bw}{\mathbf{w}}
\newcommand{\bwep}{\mathbf{w}^{\varepsilon}}
\newcommand{\bwfly}{\tilde{\mathbf{w}}}
\newcommand{\bwavg}{\mathbf{wavg}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\buprev}{\mathbf{uprev}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\bxi}{\mathbf{\xi}}
\newcommand{\dotwxb}{{\mathbf{w}}^{\mathbf{T}}\mathbf{x}_{i}+b}
\newcommand{\sumt}{\sum_{t=1}^{T} }
\newcommand{\lc}{\left(}
\newcommand{\rc}{\right)}
\newcommand{\li}{\lc i\rc}
\newcommand{\lj}{\lc j\rc}
\newcommand{\tspace}{\hspace*{2em}}
\newcommand{\tspaces}{\hspace*{1.5em}}
\newcommand{\comment}{\textcolor{red}}

\def\A{{\bf A}}
\def\a{{\bf a}}
\def\B{{\bf B}}
\def\C{{\bf C}}
\def\c{{\bf c}}
\def\D{{\bf D}}
\def\d{{\bf d}}
\def\E{{\bf E}}
\def\e{{\bf e}}
\def\f{{\bf f}}
\def\K{{\bf K}}
\def\H{{\bf H}}
\def\G{{\bf G}}
\def\I{{\bf I}}
\def\R{{\bf R}}
\def\X{{\bf X}}
\def\Y{{\bf Y}}
\def\Q{{\bf Q}}
\def\s{{\bf s}}
\def\S{{\bf S}}
\def\x{{\bf x}}
\def\y{{\bf y}}
\def\z{{\bf z}}
\def\Z{{\bf Z}}
\def\M{{\bf M}}
\def\m{{\bf m}}
\def\n{{\bf n}}
\def\U{{\bf U}}
\def\u{{\bf u}}
\def\V{{\bf V}}
\def\v{{\bf v}}
\def\W{{\bf W}}
\def\w{{\bf w}}
\def\0{{\bf 0}}
\def\1{{\bf 1}}

\def\AM{{\mathcal A}}
\def\FM{{\mathcal F}}
\def\TM{{\mathcal T}}
\def\UM{{\mathcal U}}
\def\XM{{\mathcal X}}
\def\YM{{\mathcal Y}}
\def\NM{{\mathcal N}}
\def\OM{{\mathcal O}}
\def\IM{{\mathcal I}}
\def\GM{{\mathcal G}}
\def\RB{{\mathbb R}}

\def\tx{\tilde{\bf x}}
\def\ty{\tilde{\bf y}}
\def\tz{\tilde{\bf z}}
\def\hd{\hat{d}}
\def\HD{\hat{\bf D}}
\def\hx{\hat{\bf x}}

\def\alp{\mbox{\boldmath$\alpha$\unboldmath}}
\def\bet{\mbox{\boldmath$\beta$\unboldmath}}
\def\epsi{\mbox{\boldmath$\epsilon$\unboldmath}}
\def\etab{\mbox{\boldmath$\eta$\unboldmath}}
\def\ph{\mbox{\boldmath$\phi$\unboldmath}}
\def\pii{\mbox{\boldmath$\pi$\unboldmath}}
\def\Ph{\mbox{\boldmath$\Phi$\unboldmath}}
\def\Ps{\mbox{\boldmath$\Psi$\unboldmath}}
\def\tha{\mbox{\boldmath$\theta$\unboldmath}}
\def\Tha{\mbox{\boldmath$\Theta$\unboldmath}}
\def\muu{\mbox{\boldmath$\mu$\unboldmath}}
\def\Si{\mbox{\boldmath$\Sigma$\unboldmath}}
\def\Gam{\mbox{\boldmath$\Gamma$\unboldmath}}
\def\Lam{\mbox{\boldmath$\Lambda$\unboldmath}}
\def\De{\mbox{\boldmath$\Delta$\unboldmath}}
\def\vps{\mbox{\boldmath$\varepsilon$\unboldmath}}
\newcommand{\ti}[1]{\tilde{#1}}
\def\Ncal{\mathcal{N}}
\def\argmax{\mathop{\rm argmax}}
\def\argmin{\mathop{\rm argmin}}


\def\sgn{\mathrm{sgn}}
\def\tr{\mathrm{tr}}
\def\rk{\mathrm{rank}}
\def\diag{\mathsf{diag}}
\def\dg{\mathsf{dg}}
\def\vect{\mathsf{vec}}
\def\MCAR{\mathrm{MCAR}}
\def\MSAR{\mathrm{MSAR}}
\def\etal{{\em et al.\/}\,}
\newcommand{\indep}{{\;\bot\!\!\!\!\!\!\bot\;}}

%\newtheorem{theorem}{Theorem}
%\newtheorem{lemma}{Lemma}
%\newtheorem{definition}{Definition}
%\newtheorem{proposition}{Proposition}
%\newtheorem{corollary}{Corollary}
%\newtheorem{example}{Example}

\begin{document}
\mainmatter  % start of an individual contribution

% first the title is needed
\title{Sublinear Algorithms for Penalized Logistic Regression in Massive Datasets}

% a short form should be given in case it is too long for the running head
\titlerunning{Sublinear Algorithms for Penalized Logistic Regression in Massive Datasets}

%
\author{Haoruo Peng\inst{1, 2}  \and Zhengyu Wang\inst{1, 3}  \and Edward Y. Chang\inst{1} \and Shuchang Zhou\inst{1} \and Zhihua Zhang\inst{1, 4}}
%
\authorrunning{Haoruo Peng \and Zhengyu Wang \and Edward Y. Chang \and Shuchang Zhou \and Zhihua Zhang}
% (feature abused for this document to repeat the title also on left hand pages)

\institute %
{
\inst{}
Google Research Beijing,  Beijing, China 100084 \\
\and
\inst{}
Department of Computer Science and Technology\\
Tsinghua University, Beijing, China 100084
\and
\inst{}
Institute for Interdisciplinary Information Sciences\\
Tsinghua University, Beijing, China 100084
\and
\inst{}
College of Computer Science and Technology \\
Zhejiang University, Zhejiang, China 310027 \\
\email{penghaoruo@hotmail.com wangsincos@163.com eyuchang@gmail.com georgezhou@google.com zhzhang@cs.zju.edu.cn}
}

\toctitle{Lecture Notes in Computer Science}
\tocauthor{Authors' Instructions}
\maketitle

\begin{abstract}
Penalized logistic regression (PLR) is a widely used supervised learning model.
In this paper, we consider its applications in large-scale data problems and resort to a stochastic primal-dual approach for solving PLR.
In particular, we employ a random sampling technique in the primal step and a multiplicative weights method in the dual step.
This technique leads to an optimization method with sublinear dependency on both the volume and dimensionality of training data.
We develop concrete algorithms for PLR with $\ell_2$-norm and $\ell_1$-norm penalties, respectively.
Experimental results over several large-scale and high-dimensional datasets demonstrate both efficiency and accuracy of our algorithms.
\end{abstract}

\section{Introduction} \label{sec:int}

The penalized logistic regression (PLR) model~\cite{HastieBook:SL}  plays an important role in machine learning and data mining.
The model serves for classification problems, and enjoys a substantial body of supporting theories and algorithms.
PLR is competitive with the support vector machines (SVMs) \cite{Vapnik:1998}, because it has both high accuracy and  interpretability (PLR can directly estimate a conditional class probability).

Recently, large-scale applications have emerged from many modern massive datasets.
A key characteristic of these applications is that the size of their training data is very large and data dimensionality is very high.
For example, in medical diagnostic applications~\cite{tsumoto2004mining}, both doctors and patients would like to take the advantage of millions of records over hundreds of attributes. More evidently, search engines on texts or multimedia data must handle data volume in the billion scale and each data instance is characterized by a feature space of thousands of dimensions~\cite{genkin2007large}.
Large data volume and high data dimensionality pose computational challenges to machine learning problems.

In this paper, we tackle these challenges via stochastic approximation approaches.
Stochastic approximation methods, such as stochastic gradient descent~\cite{zhang2004solving} and stochastic dual averaging~\cite{xiao2010dual}, obtain optimal generalization guarantees
with only a single pass or a small number of passes over the data.
Therefore, they can achieve a desired generalization  with runtime linear to the dataset size.
We further speed up the runtime, and propose sublinear algorithms for PLR via the use of stochastic approximation idea.
Our algorithms work at the same level of performance with traditional learning methods for PLR, but require much shorter running time.
Our methods access a single feature of training vectors instead of entire training vectors at each iteration.
This {\em sampling} approach brings much improved computational efficiency by eliminating a large number of vector multiplication operations.
By devising clever randomized algorithms, we can also enjoy the benefits of taking less number of iterations and hence accessing less number of features.
Such reduction in accessing features can substantially reduce running time as pointed out by~\cite{hazanbeating}.

Our algorithms can be easily applied to distributed storage systems~\cite{hogan1990livermore} with parallel updates on all instances.
Compared with other traditional batch algorithms, we do not require any global reduction~\cite{panda1995global} computation, which is a speedup bottleneck.
Thus, our algorithms can achieve significant speedup on massive datasets.
	
The rest of the paper is organized as follows:
Section~\ref{sec:rew} discusses some related work.
In Section~\ref{sec:plr}, we review some preliminaries and explain the setting along with the model.
In Section~\ref{sec:framework}, we present the framework of our sublinear algorithms for PLR.
In Section~\ref{sec:alg}, we depict detailed algorithms and analysis.
Section~\ref{sec:experiment} describes the datasets and the baseline of our experiments and presents the experimental results.
Finally, we offer our concluding remarks in Section~\ref{sec:concl}.

\section{Related Work} \label{sec:rew}
There are many existing techniques that address logistic regression with $\ell_1$-penalty in the literature.

The \textit{Reduced Memory Multi-pass} (RMMP) algorithm, proposed by Balakrishnan and Madigan \cite{balakrishnan2008algorithms}, is one of the most accurate and fastest convergent algorithms.
RMMP trains sparse linear classifiers on high-dimensional datasets in a multi-pass manner.
However, this algorithm has computational complexity and memory requirements that make learning on large-scale datasets infeasible.
The central idea of the work is a straightforward quadratic approximation to the likelihood function.
When the dimensionality of the data gets large, the cost of many vector-vector multiplication operations increases significantly.
Also, the quadratic approximation is added together for all instances in each iteration, and such computation inevitably requires global reduction in a distributed storage system.

The \textit{Hybrid Iterative Shrinkage} (HIS) algorithm, proposed by Shi et al. \cite{shi2008fast}, is also computationally efficient without loss of classification accuracy.
This algorithm includes a fixed point continuation phase and an interior point phase.
The first phase is based completely on memory efficient operations such as matrix-vector multiplications, while the second phase is based on a truncated Newton's method.
Thus, HIS is in the scope and constraints of traditional way of solving the optimization problem.
As RMMP has relatively better scalability and performance, we choose to use RMMP instead of HIS as our baseline for the empirical comparison in this paper.

Recently, Clarkson et al. \cite{clarkson2010sublinear} proposed a new method by taking advantage of randomized algorithms.
They presented sublinear-time approximation algorithms for optimization problems arising in machine learning, such as linear classifiers and minimum enclosing balls.
The algorithm uses a combination of a novel sampling techniques and a new multiplicative update algorithm. They also proved lower bounds which show the running times to be nearly optimal on the unit-cost RAM model.

Hazan et al. \cite{hazanbeating} exploited sublinear approximation approach to the linear SVM with $\ell_2$-penalty, from which we were inspired and borrowed some of the ideas (We generally refer to them as the ETN framework in Section~\ref{sec:framework}).
Later on, Cotter et al. \cite{cotter2012kernelized} extended the work to kernelized SVM cases.
In \cite{hazan2011optimal}, Hazan et al. applied the sublinear approximation approach for solving ridge ($\ell_2$-regularized) and lasso ($\ell_1$-regularized) linear regression.
Garber and Hazan \cite{garberapproximating} developed the method in semidenfinite programming (SDP).

\section{Penalized Logistic Regression Models} \label{sec:plr}
Logistic regression is a widely used method for solving classification problems.
In this paper, we are mainly concerned with the binary classification problem.  	
Suppose that we are given a set of training data $\XM=\{(\x_i, y_i): i=1, \ldots, n\}$ where $\x_i \in \RB^d$ are input samples and $y_i \in \{-1, 1\}$ are the corresponding labels.
For simplicity, we let $\X=[{\x}_{1}, {\x}_{2}, \ldots, {\x}_n]^{T}$ and $\y=(y_1, y_2, \ldots, y_n)^T$.
In the logistic regression model, the expected value of $y_i$ is given by
\[
P(y_i|\x_i)= \frac{1}{1+ \exp(- y_i(\x_i^T \w + b))} \triangleq g_i(y_i),
\]
where $\w=(w_1, \ldots, w_d)^T \in \RB^d$ is a regression vector and $b\in \RB$ is an offset term.
The $\log$ likelihood function $F(\w, b; \XM)$ on the training data is given as
\[
F(\w, b| \XM)
=   \sum_{i=1}^n \log g_i(y_i).
\]

Under the penalized framework, one imposes a prior $p(\w)$ to $\w$. This allows us to address the maximum a posteriori (MAP) estimation for $\w$ as    	 
\begin{equation} \label{eqn:3}
 \max_{\bw ,b} \; \big\{ \log\, p(\bw, b | \XM) \propto F(\w, b| \XM)+ \log\, p(\bw) \big\}.
\end{equation}

In this paper, we consider Gaussian and Laplace priors for $\w$, which in turn induce the $\ell_2$ and $\ell_1$ penalties for $\w$, respectively.
	
\subsection{The $\ell_2$-Penalty Logistic Regression}
	
We assume that $\w$ follows a Gaussian distribution with mean $\0$ and covariance matrix $\lambda \I_d$ where $\I_d$ is the $d{\times}d$ identity matrix, i.e. $\w \thicksim N(\0, \lambda \I_d)$. In this case, since	
\[
	\log\, p(\bw) =\frac{d}{2}\,\log {\frac{\lambda}{2\pi}}-\frac{\lambda}{2} \|\bw \|_2^{2},
\]
we can equivalently formulate the optimization problem in (\ref{eqn:3}) as
\begin{equation} \label{eqn:4}
	\max_{\bw ,b} \; \Big\{F(\w, b| \XM) - \frac{\lambda}{2}  \|\bw\|_2^{2} \Big\}.
\end{equation}
(\ref{eqn:4}) shows us that the problem reduces to an optimization problem with an $\ell_2$-penalty.
	
\subsection{The $\ell_1$-Penalty Logistic Regression}
	
In the second case, we impose a Laplace prior for $\w$, whose density is given by
\[	
\log\,p\lc\bw \rc=d\,\log\frac{\gamma}{2}-\gamma{\|\bw\|}_{1}.
\]
With this prior, the optimization problem in (\ref{eqn:3}) is equivalent to the following problem with the $\ell_1$-penalty.
\begin{equation} \label{eqn:5}
	\max_{\bw ,b} \;  \big\{F(\w, b|\XM)- \gamma{\|\bw \|}_{1}\big\}.	
\end{equation}

The advantage of $\ell_1$-penalty over $\ell_2$-penalty is its utility in sparsity modeling \cite{tibshirani1996regression} .
Thus, $\ell_1$-penalty logistic regression can serve for both classification and feature selection simultaneously.
	
\section{Methodology} \label{sec:framework}
	
In this section, we first develop an approach to sublinear learning for $\ell_2$-penalty logistic regression.
We then extend the approach to $\ell_1$-penalty case by adding certain conditions to achieve sparseness.
Our approach is inspired by the \textit{Elad-Tomer-Nathan} (ETN) framework in \cite{hazanbeating}, a hybrid framework that deals with both hard margin and soft margin.
Roughly speaking, our approach consists of three steps: deriving the hard margin and soft margin from the objective function, computing the derivative, and applying the ETN framework.

\subsection{From $\ell_2$-Penalty to Soft Margin}	

We treat the objective function (\ref{eqn:4}) as two parts: likelihood and penalty. With this in mind, we introduce the notion of hard margin and soft margin to respectively represent these two parts.

In particular, we consider an alternative optimization problem under an $\varepsilon$-suboptimal solution basis. That is,
\begin{equation} \label{eqn:7}
\max_{\bw ,b,\xi_i\geq 0 } \, \min_{i\in\left\{1, \cdots, n\right\}}  f_i\lc \bw, b \rc + \xi_i \;  \mbox{ s.t. } \|\bw\|_2 \leq 1 \;  \mbox{ and } \; \sum_{i=1}^{n}\xi_i\leq n\nu.
\end{equation}
In (\ref{eqn:7}) $f_i(\w, b) = \log g_i(y_i)$ is the hard margin part, while $\xi_i$ is the soft margin part, and we have $\nu = -\frac{\sum_{i=1}^{n}f_i\lc \bw, b \rc}{n\|\bw\|_2}$.
	
The following lemma shows the equivalent relationship between (\ref{eqn:4}) and (\ref{eqn:7}).

\begin{lemma} \label{lem:1}
	Let $(\bwep, b^{\varepsilon},\bxi^\varepsilon)$ be an $\varepsilon$-suboptimal solution to the optimization problem (\ref{eqn:7}) with optimal value $\kappa$, and
	consider the rescaled solution $\bwfly=\bwep /\kappa,\tilde{b}=b^{\varepsilon}/\kappa,\tilde{\bxi}=\bxi^\varepsilon /\kappa$.
The the following two inequalities hold.
	\[
	\|\bwfly\|_2\leq \frac{1}{1-\varepsilon\|\bw\|_2}\|\bw\|_2 \quad \mbox{ and } \quad F\lc \bwfly, \tilde{b} \rc \leq \frac{1}{1-\varepsilon\|\bw\|_2} F\lc \bw, b \rc.
	\]
\end{lemma}

The proof of Lemma \ref{lem:1} is given in Appendix A.
Lemma~\ref{lem:1} shows that solving (\ref{eqn:7}) exactly yields Pareto optimal solutions of (\ref{eqn:4}).
Moreover, if we solve (\ref{eqn:7}) via approximation, we obtain a suboptimal solution.
As for parameters $\nu$ and $\xi_i$, we only need to consider $0\leq\nu\leq1$ and $0\leq\xi_i\leq2$.
	
\subsection{Derivative of Objective Function}
	
For hard margin, we compute the derivative  of $f_i(\bw,b)$ with respect to $\bw$.
In this case, we have
	\begin{equation} \label{eqn:10}
	f_i (\bw, b) = \log g_i(y_i).
	\end{equation}

The first partial derivative of (\ref{eqn:10}) is as follows
	\begin{eqnarray} \label{eqn:11}
	coef &\triangleq & \frac{\partial f_i\lc\bw,b\rc}{\partial \bw}= - \frac{\partial\log  [1+\exp(-y_i ( \dotwxb))] } {\partial \bw}  \\
	&= &\frac{\mathbf{x}_i y_i \exp(-y_i  (\dotwxb) ) }{1+ \exp(-y_i \lc \dotwxb \rc)}
	=y_i g_i\lc -y_i  \rc\mathbf{x}_i.  \nonumber
	\end{eqnarray}

In order to extend this result to $\ell_1$-penalty logistic regression,
we only need to adjust the derivative of $f_i(\w, b)$ with respect to $\w$.
In this case, we need to use the sub-differential of $\|\bw\|_1$.  First, we define  a signum multi-function of $t\in\mathbb{R}$ as
	\[
	S(t) \triangleq \partial |t| =
		\begin{cases}
 		\{+1\} & \text{ if } t >0  \\
 		\left[-1,1\right]  & \text{ if } t=0  \\
 		\{-1\} & \text{ if } t<0.
		\end{cases}
	\]

For $\mathbf{x}\in\mathbb{R}^d$, we define $S\lc\mathbf{x}\rc \in \mathbb{R}^d$ with $(S(\x))_i=S(x_i)$ for $i=1, \ldots, d$.
Then the derivative of (\ref{eqn:5}) is
	\begin{equation}  \label{eqn:100}
	coef=y_i g_i\lc -y_i  \rc\mathbf{x}_i-\gamma S\lc\bw\rc.
	\end{equation}
	
	Eqn.~(\ref{eqn:100}) is the simple and general form  for $coef$.
		
\subsection{The ETN Framework}
	
The \textit{Elad-Tomer-Nathan} framework~\cite{hazanbeating} is a hybrid method to handle hard margin and soft margin separately and simultaneously.
The ETN framework enjoys the property of fast convergence for both hard margin and soft margin.
	
Each iteration of the method works in two steps.
The first one is the \textit{stochastic primal update}:

\begin{enumerate}
\item[{(1)}] \; An instance $i\in \{1,\ldots, n\}$ is chosen according to a probability vector $\bp$;
\item[{(2)}] \; The primal variable $\bw$ is updated according to the derivative of $f_i(\bw,b)$ and the soft margin, via an online update with regret.
\end{enumerate}

The second one is the \textit{stochastic dual update}:
\begin{enumerate}
\item[{(1)}] \; A stochastic estimate of $f_i(\bw,b)$ plus the soft margin is obtained, which can be computed in $O(1)$ time per term;
\item[{(2)}] \; The probability vector $\bp$ is updated based on the above computed terms by using the \textit{Multiplicative Updates} (MW) framework~\cite{arora2005multiplicative} for online optimization over the simplex.
\end{enumerate}
	
\section{Algorithms and Analysis} \label{sec:alg}

We use the following notations in our algorithms and analysis.

$clip\lc \cdot \rc$ is a projection function defined as follows:
	\[
	clip\lc a,b \rc \triangleq \max \lc \min \lc a,b \rc ,-b\rc \,\,\,\,\,\, a,b \in \mathbb{R}.
	\]

$\sgn \lc \cdot \rc$ is the sign function; namely,
	
	\[
	\sgn \lc x \rc =
		\begin{cases}
 		+1 & \text{ if } x>0  \\
 		0  & \text{ if } x=0  \\
 		-1 & \text{ if } x<0.
		\end{cases}
	\]

$g\lc \cdot \rc$ is the logistic function; namely,
	\[
	g \lc x \rc=\frac{1}{1+e^{-x}}
	\]

We let $\Lambda$ be the $\mathbb{R}_{n}$ Euclidean space which meets the following conditions:
	\[
	\Lambda=\left\{ \bxi\in\mathbb{R}_{n} \, | \, \forall i, \, 0\leq{\xi}_{i}\leq 2, \, {\|\xi \|}_{1}\leq \nu n  \right
	\}.
	\]

\subsection{The Sublinear Algorithm for $\ell_2$-Penalty Logistic Regression} \label{sec:l2alg}
	
	\begin{table} [ht]
	\begin{tabular}{l}
	\hline\noalign{\smallskip}
	\textbf{Algorithm 1} SLLR-L2 \\
	\noalign{\smallskip}
	\hline
	\noalign{\smallskip}
		1:    Input: $\varepsilon>0, 0\leq\nu\leq1, X\in\mathbb{R}^{n\times d}, Y\in\mathbb{R}^{n} $ \\
		2:    Let $T\leftarrow{1000}^{2}{\varepsilon}^{-2}\log n, \eta\leftarrow\sqrt{\log\lc n\rc/T}$ \\
		3:    \tspace ${\mathbf{u}}_{0}\leftarrow{\mathbf{0}}_{d},{\bw}_{1}\leftarrow{\mathbf{0}}_{d},{\mathbf{\bq}}_{1}\leftarrow{\mathbf{1}}_{n},{b}_{1}\leftarrow 0$\\
		4:    \textbf{for} $t=1$ to $T$ \textbf{do} \\
		5:    \tspace ${\bp}_{t}\leftarrow{\bq}_{t}/{\|{\bq}_{t}\|}_{1}$ \\
		6:    \tspace Choose ${i}_{t}\leftarrow i$ with probability $\bp(i)$ \\
		7:    \tspace Let $coef={y}_{{i}_{t}}g\lc-{y}_{{i}_{t}}\lc {{\bw}_{t}}^{T}{\mathbf{x}}_{i_t}+{b}_{t} \rc\rc$ \\
		8:    \tspace Let ${\bu}_{t}\leftarrow {\bu}_{t-1}+\frac{coef}{\sqrt{2T}}{\mathbf{x}}_{{i}_{t}}$ \\
		9:    \tspace\tspace ${\bxi}_{t}\leftarrow \argmax_{\bxi\in \Lambda}\lc{{\bp}_{t}}^{T}\bxi\rc$ \\
		10:   \tspace\hspace*{1.2em} ${b}_{t}\leftarrow \sgn\lc {{\bp}_{t}}^{T}\mathbf{y}\rc$ \\
		11:   \tspace ${\bw}_{t}\leftarrow {\bu}_{t}/\max \left\{1,\|{\bu}_{t}\|_2 \right\}$ \\
		12:   \tspace Choose ${j}_{t}\leftarrow j$ with probability ${{\bw}_{t}\lj}^{2}/{\|{\bw}_{t}\|_2}^{2} $ \\
		13:   \tspace \textbf{for} $i=1$ to $n$ \textbf{do} \\
		14:   \tspace\tspace $\sigma \leftarrow \mathbf{x}_{i} \lc {j}_{t}\rc{\|{\bw}_{t}\|_2}^{2}/{\bw}_{t}\lc {j}_{t} \rc+{\bxi}_{t}\li+{y}_{i}{b}_{t}$ \\
		15:   \tspace\tspace $\hat{\sigma} \leftarrow clip\lc \sigma,1/\eta \rc$ \\
		16:   \tspace\tspace ${\bq}_{t+1}\li \leftarrow {\bq}_{t}\li\lc 1-\eta\hat{\sigma} + {\eta}^{2}{\hat{\sigma}}^{2} \rc$ \\
		17:   \tspace \textbf{end for} \\
		18:   \textbf{end for} \\
		19:   Output: $\bar{\bw}=\frac{1}{T}\sum_{t}{\bw}_{t},\bar{b}=\frac{1}{T}\sum_{t}{b}_{t}$ \\
	\hline
	\end{tabular} 	
	\label{alg:1}
	\end{table}
	
We give the sublinear algorithm for $\ell_2$-penalty logistic regression in Algorithm~1.	
In the pseudo-code of Algorithm~1, line 5 to line 11 is the primal part, where $coef$ is the estimator of the derivatives and $\bxi$ is the soft margin.
Line 12 to line 17 is the dual part, where $\sigma$ serves as an estimator of $f_i\lc\bw,b\rc$ plus the soft margin. $\sigma$ also serves as the derivative of $\bp(i)$.
Although the computation of line 15 and 16 makes $\hat{\sigma}$ a biased approximation, it is critical to the stability of the algorithm.
The resulting bias is negligible in our approach. This can be shown in the experimental results in~\cite{hazanbeating}.
Because of the similarity between our SLLR-L2 and SVM-SIMBA presented in \cite{hazanbeating}, we can naturally invoke the statement here.

Note that the update of ${\bxi}_{t}$ in line 9 can be accomplished by using a simple greedy algorithm in $O(n)$ time.
We can always set ${\bxi}_{t}\li=2$ corresponding to the first $[\frac{\nu n}{2}]$ number of largest entries $\bp\li$ of ${\bp}_{t}$ with respect to $i$.
Then the residue $\nu n-2[\frac{\nu n}{2}]$ is assigned to ${\bxi}_{t}(\hat{i})$, where $\hat{i}$ is exactly the index of the $[\frac{\nu n}{2}]+1$ largest one in $\bp_t$.
Finally, we put ${\bxi}_{t}\li=0$ elsewhere.
	
\subsection{The Sublinear Algorithm for $\ell_1$-Penalty Logistic Regression}
	
	\begin{table}[ht]
	\begin{tabular}{l}
	\hline\noalign{\smallskip}
	\textbf{Algorithm 2} SLLR-L1 \\
	\noalign{\smallskip}
	\hline
	\noalign{\smallskip}
		1:    Input: $\varepsilon>0, \gamma>0, X\in\mathbb{R}^{n\times d}, Y\in\mathbb{R}^{n}$ \\
		2:    Let $T\leftarrow{1000}^{2}{\varepsilon}^{-2}\log n, \eta\leftarrow\sqrt{\log\lc n\rc/T}$ \\
		3:    \tspace ${\mathbf{u}}_{0}\leftarrow{\mathbf{0}}_{d},{\bwavg}_{0}\leftarrow{\mathbf{0}}_{d},{\mathbf{\bq}}_{1}\leftarrow{\mathbf{1}}_{n},{b}_{1}\leftarrow 0$\\
		4:    \textbf{for} $t=1$ to $T$ \textbf{do} \\
		5:    \tspace ${\bp}_{t}\leftarrow{\bq}_{t}/{\|{\bq}_{t}\|}_{1}$ \\
		6:	  \tspace $\buprev_t\leftarrow\bu_{t-1}$ \\
		7:    \tspace Choose ${i}_{t}\leftarrow i$ with probability $\bp(i)$ \\
		8:    \tspace Let $coef={y}_{{i}_{t}}g\lc-{y}_{{i}_{t}}\lc {{\bwavg}_{t-1}}^{T}{\mathbf{x}}_{i_t}+{b}_{t} \rc\rc$ \\
		9:    \tspace Let ${\bu}_{t}\leftarrow {\bu}_{t-1}+\frac{coef}{\sqrt{2T}}{\mathbf{x}}_{{i}_{t}}$ \\
		10:   \tspaces\tspace ${b}_{t}\leftarrow \sgn\lc {{\bp}_{t}}^{T}\mathbf{y}\rc$ \\
		11:   \tspaces \textbf{for} $j=1$ to $d$ \textbf{do} \\
		12:   \tspaces\tspace \textbf{if} $\buprev_t\lj>0$ \textbf{and} $\bu_t\lj>0$ \\
		13:	  \tspaces\tspace\tspace $\bu_t\lj=\max \lc \bu_t\lj-\gamma ,0 \rc$ \\
		14:	  \tspaces\tspace \textbf{if} $\buprev_t\lj<0$ \textbf{and} $\bu_t\lj<0$ \\
		15:   \tspaces\tspace\tspace $\bu_t\lj=\min \lc \bu_t\lj+\gamma ,0 \rc$ \\
		16:   \tspaces \textbf{end for} \\
		17:   \tspaces ${\bw}_{t}\leftarrow {\bu}_{t}/\max \left\{1,\|{\bu}_{t}\|_2 \right\}$ \\
		18:   \tspaces ${\bwavg}_{t}\leftarrow \frac{t-1}{t}{\bwavg}_{t-1}+\frac{1}{t}\bw_t$ \\
		19:   \tspaces Choose ${j}_{t}\leftarrow j$ with probability ${{\bw}_{t}\lj}^{2}/{\|{\bw}_{t}\|_2}^{2} $ \\
		20:   \tspaces \textbf{for} $i=1$ to $n$ \textbf{do} \\
		21:   \tspaces\tspace $\sigma \leftarrow \mathbf{x}_{i} \lc {j}_{t}\rc{\|{\bw}_{t}\|_2}^{2}/{\bw}_{t}\lc {j}_{t} \rc+{y}_{i}{b}_{t}$ \\
		22:   \tspaces\tspace $\hat{\sigma} \leftarrow clip\lc \sigma,1/\eta \rc$ \\
		23:   \tspaces\tspace ${\bq}_{t+1}\li \leftarrow {\bq}_{t}\li\lc 1-\eta\hat{\sigma} + {\eta}^{2}{\hat{\sigma}}^{2} \rc$ \\
		24:   \tspaces \textbf{end for} \\
		25:   \textbf{end for} \\
		26:   Output: $\bwavg_t,\bar{b}=\frac{1}{T}\sum_{t}{b}_{t}$ \\
	\hline
	\end{tabular}
	\end{table}
	
	In Algorithm~2, we give the sublinear approximation procedure for $\ell_1$-penalty logistic regression.
	Here, we let $\buprev_t$  be $\bu_{t-1}$ in the previous iteration.
	We achieve sparseness by adding pseudo-code from Line 11 to Line 16.

	To make use of (\ref{eqn:100}), we introduce some techniques to ensure the numerical convergence and stability.
	Considering the update computation in the primal step, we should make the following three rules.
	
	\begin{enumerate}
	\item[{(1)}] \; When $\bu_t(j)=0$, we do not apply $-\gamma S(\bw)$ and simply make the value 0 by default.
	\item[{(2)}] \; In order to apply  $-\gamma S(\bw)$ for sparseness, we set $\bu_t(j)=0$, if it changes between positive values and negative values after applying the derivative.
	                This is showed in Line 13 and Line 15.
	\item[{(3)}] \; To avoid a $\mathbf{0}$ vector when $\gamma$ is large, we need to determine the derivative by a trend, not a single point. Thus, we consider two consecutive update steps of $\bu_t(j)$. Line 12 and Line 14 ensure that if $\bu_t(j)$ and $\bu_{t-1}(j)$ are either both positive values or both negative ones, we apply the derivative, otherwise we do not change $\bu_t(j)$. This is a logical approximation, and enables the small variance of values changing between positive values and negative ones.
	\end{enumerate}
	
	For $\ell_1$-penalty logistic regression, the derivative is much more sensitive with respect to $\bw_t$, as it is sparse in the computation. So in line 8, when we compute $coef$, we change $\bw_t$ to $\bwavg_{t-1}$ in order to make our algorithm more computationally stable.
	
\subsection{Running Time Analysis}
	
	We now formally describe the MW algorithm and give theorems for running times of our algorithms.
	
	\begin{definition}
	(MW algorithm)~\cite{clarkson2010sublinear}. Consider a sequence of vectors $\mathbf{v}_1,...,\mathbf{v}_T\in\mathbb{R}^d$ and a parameter $\eta>0$. The Multiplicative Weights (MW) algorithm is defined as follows: let $\bw_1 \leftarrow \mathbf{1}_n$, and for $t\geq 1$,
	\[
	\bp_t \leftarrow \bw_t/\|\bw_t\|_1, \,\,\,\, and \,\,\,\, \bw_{t+1}(i) \leftarrow \bw_t(i)\lc 1-\eta\mathbf{v}_t(i)+\eta^2\mathbf{v}_t(i)^2 \rc.
	\]
	\end{definition}
	
	The following lemma establishes a regret bound for the MW algorithm.
	
	\begin{lemma} \label{lem:2}
	(The Variance MW Lemma)~\cite{clarkson2010sublinear}. The MW algorithm satisfies
	\[
	\sumt \bp_t^T\mathbf{v}_t \leq \min_{i\in\left\{1,...,n\right\} } \sumt \max\{\mathbf{v}_t(i),-\frac{1}{\eta}\}+\frac{\log n}{\eta}+\eta\sumt\bp_t^T \mathbf{v}_t^2
	\]
	\end{lemma}
	
The following theorems give the running times of Algorithm~1 and Algorithm~2, respectively.
	
	\begin{theorem}
	The SLLR-L2 algorithm returns an $\varepsilon$-approximate solution to the optimization problem of (\ref{eqn:7}) with probability at least $1/2$. Its running time is $ \tilde{O}\lc \varepsilon^{-2}\lc n+d\rc \rc $.
	\end{theorem}
	
	We give the proof of Theorem~1 in Appendix B. Because the SLLR-L1 is essentially an extension of SLLR-L2, the running time is the same, and we omit the proof of Theorem~2 in this paper due to length constraint.
	
	\begin{theorem}
	The SLLR-L1 algorithm returns an $\varepsilon$-approximate solution to the optimization problem of (\ref{eqn:5}) with probability at least $1/2$. Its running time is $ \tilde{O}\lc \varepsilon^{-2}\lc n+d\rc \rc $
	\end{theorem}
	
\section{Experiments} \label{sec:experiment}

In this section, we conduct an empirical analysis of our algorithms.
Particularly, we illustrate test errors in terms of feature accesses and convergence in terms of MAP.
As illustrated in Section~\ref{sec:int}, feature accesses are the main cost in computation.
They are good indicators of running time and best demonstrate the efficiency of the proposed algorithms.
For SLLR-L2, we choose SVM-SIMBA algorithm~\cite{hazanbeating} as a comparison baseline.
For SLLR-L1, we choose the state-of-the-art RMMP~\cite{balakrishnan2008algorithms} algorithm, a popular method for solving logistic regression with $\ell_1$-penalty.
	
We choose three open datasets to run all four test programs:	
The	\textbf{NewsGroup} dataset (after proper preprocessing) has 893 features and 1985 instances. We split it into a training set of 1390 instances and a test set of 595 instances.	
The	second test dataset is the \textbf{Gisette} \cite{guyon2004result} dataset, which has 5000 features and 7000 instances. We split it into a training set of 6000 instances and a test set of 1000 instances. 
The	third and final test dataset is the \textbf{ECUE Spam} \cite{DelanyKBS05} dataset, which has 197650 features and 10978 instances (after proper preprocessing). We split it into a training set of 9000 instances and a test set of 1978 instances.
We randomly repeat such split 20 times and our analysis is based on the average performance of 20 repetitions.

\subsection{Analysis of Performance}

\begin{figure}[ht] \label{fig:01}
    \begin{tabular}{cc}
\hspace{-0.3cm}	\includegraphics[height=4cm,width=6.5cm]{l1_ng.eps}
&\hspace{-0.6cm}	\includegraphics[height=4cm,width=6.5cm]{rmmp_ng2.eps} \\
(a) SLLR-L1 & (b) RMMP \\
\hspace{-0.3cm}	\includegraphics[height=4cm,width=6.5cm]{l2_ng.eps}
&\hspace{-0.6cm}	\includegraphics[height=4cm,width=6.5cm]{svm_ng2.eps}
	\\
	(c)  SLLR-L2 & (d)  SVM-SIMBA \\
	\end{tabular}
\caption{The test error, as a function of the number of feature accesses, on the \textbf{NewsGroup} dataset. For both SLLR-L1 and SLLR-L2, we set $\varepsilon=0.5$.}
\end{figure}

\begin{figure}[tb] \label{fig:02}
    \begin{tabular}{cc}
\hspace{-0.3cm}   \includegraphics[height=4cm,width=6.5cm]{l1_gist.eps}
&\hspace{-0.6cm}\includegraphics[height=4cm,width=6.5cm]{rmmp_gist2.eps} \\
(a) SLLR-L1 & (b) RMMP \\
\hspace{-0.3cm}	\includegraphics[height=4cm,width=6.5cm]{l2_gist.eps}
&\hspace{-0.6cm}\includegraphics[height=4cm,width=6.5cm]{svm_gist2.eps} \\
	(c)  SLLR-L2 & (d)  SVM-SIMBA \\
	\end{tabular}
\caption{The test error, as a function of the number of feature accesses, on the \textbf{Gisette} dataset. For both SLLR-L1 and SLLR-L2, we set $\varepsilon=0.5$.}
\end{figure}
	
\begin{figure}[tb] \label{fig:03}
    \begin{tabular}{cc}
\hspace{-0.3cm}	\includegraphics[height=4cm,width=6.5cm]{l1_spam.eps}
&\hspace{-0.6cm}\includegraphics[height=4cm,width=6.5cm]{rmmp_spam2.eps} \\
(a) SLLR-L1 & (b) RMMP \\
\hspace{-0.3cm}	\includegraphics[height=4cm,width=6.5cm]{l2_spam.eps}
&\hspace{-0.6cm}\includegraphics[height=4cm,width=6.5cm]{svm_spam2.eps} \\
	(c)  SLLR-L2 & (d)  SVM-SIMBA \\
	\end{tabular}
\caption{The test error, as a function of the number of feature accesses, on the \textbf{ECUE Spam} dataset. For both SLLR-L1 and SLLR-L2, we set $\varepsilon=0.5$.}
\end{figure}
	
In all three experiments, we tuned parameters $\nu$ and $\gamma$ of each algorithm based on the cross-validation method~\cite{kohavi1995study}.
Note that our algorithms assume random access to features (as opposed to instances), thus it is not meaningful to compare the test error as a function of the number of iterations of each algorithm. Instead, according to our computational model, we compare the test error as a function of the number of feature accesses of each algorithm.
The results, averaged over 20 repetitions, are presented in Figure 1, 2 and 3.
	
As can be seen from the figures, the performance of our SLLR-L2 algorithm is competitive with that of SIMBA on all the three datasets.
With respect to $\ell_2$-penalty, our experiments show that our SLLR-L2 algorithm can achieve a similar performance with SIMBA.
With respect to $\ell_1$-penalty, our SLLR-L1 algorithm can achieve a same level of performance as RMMP.
Our SLLR-L1 algorithm has a fast convergence rate, which enables us to achieve an acceptable test error with much fewer feature accesses in comparison with RMMP (basically a batch algorithm).
	
\subsection{Analysis of Convergence}
	
\begin{figure}[ht] \label{fig:04}
    \begin{tabular}{cc}
\hspace{-0.9cm}	\includegraphics[height=3.5cm,width=7cm]{map_l1_ng.eps}
&\hspace{-0.5cm}\includegraphics[height=3.5cm,width=7cm]{map_l2_ng.eps} \\
\hspace{-0.9cm}	\includegraphics[height=3.5cm,width=7cm]{map_l1_gist.eps}
&\hspace{-0.5cm}\includegraphics[height=3.5cm,width=7cm]{map_l2_gist.eps} \\
\hspace{-0.9cm}	\includegraphics[height=3.5cm,width=7cm]{map_l1_spam.eps}
&\hspace{-0.5cm}\includegraphics[height=3.5cm,width=7cm]{map_l2_spam.eps} \\
(a)SLLR-L1 and RMMP for $\ell_1$-penalty & (b)SLLR-L2 for $\ell_2$-penalty
	\end{tabular}
\caption{The MAP, averaged over 20 random repetitions, as a function of the number of feature accesses, on the \textbf{NewsGroup}(first row), \textbf{Gisette}(second row), \textbf{ECUE Spam}(third row) datasets. For both SLLR-L1 and SLLR-L2, we set $\varepsilon=0.5$.}
\end{figure}
	
Figures~4 shows the convergence of our algorithms.
With respect to $\ell_2$-penalty, we do not consider SVM-SIMBA, as its optimization objective function is not comparable with that of SLLR-L2.
As the variance of MAP in different experiments is so small and does not contain much information, they are not shown in the figure for simplicity.
The convergence of SLLR-L2 algorithm is very fast. There is a rapid growing of MAP, and it happens in a very early stage.
With respect to $\ell_1$-penalty, the optimum value achieved by our SLLR-L1 and RMMP, a state-of-art algorithm with a remarkable accuracy on MAP, is very close.
Our SLLR-L1, though not strictly better than RMMP on accuracy, has a very small gap away from the optimum solution and it is acceptable considering the test error results shown previously.
Moreover, our SLLR-L1 has the advantage of achieving its local optimum value much earlier than RMMP.
This is because our approach loosely takes anywhere from 100 to 1000 times fewer feature accesses than RMMP.

\section{Conclusion} \label{sec:concl}

In this paper, we have presented two efficient algorithms to solve PLR through the use of a stochastic approximation approach.
In particular, we have devised two sublinear algorithms for the logistic regression models with $\ell_2$-penalty and $\ell_1$-penalty, respectively.
Experimental results have illustrated that our algorithms work well on massive datasets and have significant computational performance over other existing methods for PLR.
Our algorithms can also be easily applied to distributed storage systems with parallel update on all instances.

\section*{Appendix}

\subsection*{A. Proof of Lemma \ref{lem:1} }
The method we use here is similar to that in~\cite{hazanbeating}.
\begin{proof}
	We first consider the solution which is given by $\bw^*=\bw /\|\bw\|_2,b^*=b/\|\bw\|_2,\bxi^*=\bxi/\|\bw\|_2$. So we have $ \sum_{i=1}^n \xi_i^* =F\lc\bw,b\rc/\|\bw\|_2=n\nu$.
	Then the optimal value is given by:
	\[
	\kappa^*=\min_{i\in\left\{1,\cdots,n\right\}} \frac{f_i(\bw,b)+\xi_i}{\|\bw\|_2}=\frac{1}{\|\bw\|_2}.
	\]
	By the assumption on the suboptimality of $\bwep,b^{\varepsilon},\bxi^\varepsilon$, we have $ \kappa \geq \kappa^* -\varepsilon= \frac{1}{\|\bw\|_2} -\varepsilon$, from which we can conclude that:
	\[
	\|\bwfly\|_2=\frac{\|\bw\|_2}{\kappa} \leq \frac{\|\bw\|_2}{1/\|\bw\|_2-\varepsilon} \leq \frac{1}{1-\varepsilon\|\bw\|_2}\|\bw\|_2.
	\]
	From the form of the objective function, we also have:
	\[
	F\lc\bwfly,\tilde{b}\rc \leq \sum_{i=1}^n \tilde{\xi}_i \leq \frac{n\nu}{\kappa} \leq \frac{F\lc\bw,b\rc}{\|\bw\|_2}\cdot\frac{1}{1/\|\bw\|_2-\varepsilon}=\frac{F\lc\bw,b\rc}{1-\varepsilon\|\bw\|_2}.
	\]
	
\end{proof}

\subsection*{B. Proof of Theorem 1 }
The method we use here is similar to that in~\cite{hazanbeating}. \\
We first introduce some basic lemmas to simplify the proof.
	\begin{lemma} \label{lem:3}
	For $\sqrt{\log(n)/T} \leq \eta \leq 1/6$ with probability at least $1-O(1/n)$, it holds that
	\[	
	\max_{i\in\left\{1,\cdots,n\right\}} \sumt \mathbf{v}_t(i)-\sumt\left[ \mathbf{x}_i^T\bw_t+\bxi_t(i)\right] \leq 4 \eta T,
	\]
	\[	
	\left| \sumt \bp_t^T\mathbf{v}_t-\sumt\bp_t^T \lc \mathbf{X}\bw_t+\bxi_t \rc \right|\leq 4 \eta T.
	\]
	\end{lemma}
	\begin{lemma} \label{lem:5}
	For $ \sqrt{\log(n)/T} \leq \eta \leq 1/4 $ with probability at least $1-O(1/n)$, it holds that	
\[	
 \left| \sumt \mathbf{x}_{i_t}^T\bw_t-\sumt\bp_t^T \mathbf{X}\bw_t\right|\leq 12\eta T \mbox{ and }
	\left| \sumt \mathbf{x}_{i_t}^T\bw^*-\sumt\bp_t^T \mathbf{X}\bw^*\right|\leq 12\eta T.
\]
	\end{lemma}
	\begin{lemma} \label{lem:6}
	With probability at least 3/4, it holds that
	\[	
	\sumt \bp_t^T \mathbf{v}_t^2 \leq 48T
	\]
	\end{lemma}
We omit the proofs because they can be immediately obtained from \cite{hazanbeating} with some minor modifications.

\begin{proof}
	
Firstly, we  prove the running time.
	Algorithm~1 makes $T=O(\varepsilon^{-2}\log n )$ iterations.
	Each iteration consists of two steps: the primal update and the dual update.
	The primal update contains a $\ell_1$-sampling process for the choice of $i_t$ ($O(n)$ time), and the update of $\bw_t$ ($O(d)$ time). The update of $\bxi_t$ can be done using a simple greedy algorithm which takes $O(n)$ time.
	The primal update contains a $\ell_2$-sampling process for the choice of $j_t$ ($O(d)$ time), and an update of $\bp$ ($O(n)$ time).
	Altogether, each iteration takes $O(n+d)$ time and the overall running time is therefore $ \tilde{O}\lc \varepsilon^{-2}\lc n+d\rc \rc $. \\
	
	Next, we analyze the output quality of Algorithm~1.
	Let $\gamma^*$ be the value of the optimal solution of (\ref{eqn:7}). Then, by the definition we have
	\begin{equation} \label{eqn:12}
	\sumt\bp_t^T \lc \mathbf{X}\bw^*+\bxi^* \rc \geq T\gamma^*.
	\end{equation}
	In the primal part of the algorithm we have
	\[
	\sumt\mathbf{x}_{i_t}^T\bw_t \geq \sumt\mathbf{x}_{i_t}^T\bw^*-2\sqrt{2T}.
	\]
	Thus, from Lemma \ref{lem:5} we obtain that with probability $1-O(1/n)$,
	\[
	\sumt\bp_t^T\mathbf{X}\bw_t \geq \sumt\bp_t^T\mathbf{X}\bw^*-2\sqrt{2T}-24\eta T.
	\]
	On the other hand,
	\[
	\sumt\bp_t^T\bxi_t \geq \sumt\bp_t^T\bxi_t^*,
	\]
	since $\bxi_t$ is the maximizer of $\bp_t^T\bxi$, and recalling (\ref{eqn:12}), we get the following lower bound:
	\begin{equation} \label{eqn:13}
	\sumt\bp_t^T \lc \mathbf{X}\bw_t+\bxi_t \rc \geq T\gamma^* -2\sqrt{2T}-24\eta T.
	\end{equation}
	In the dual part of the algorithm, applying Lemma \ref{lem:2} on the clipped vector $\mathbf{v}_t$, we have that
	\[
	\sumt\bp_t^T\mathbf{v}_t \leq \min \sumt \mathbf{v}_t+\frac{\log n}{\eta}+\eta\sumt\bp_t^T \mathbf{v}_t^2,
	\]
	and together with Lemma \ref{lem:3}, we get that with probability $1-O(1/n)$,
	\[
	\sumt\bp_t^T \lc \mathbf{X}\bw_t+\bxi_t \rc \leq \min \sumt\lc \mathbf{X}\bw_t+\bxi_t \rc+\frac{\log n}{\eta}+\eta\sumt\bp_t^T \mathbf{v}_t^2+8\eta T.
	\]
	Hence, from Lemma \ref{lem:6}, we obtain the following upper bound, with probability more than $\frac{3}{4}-O(1/n)\geq \frac{1}{2}$
	\begin{equation} \label{eqn:14}
	\sumt\bp_t^T \lc \mathbf{X}\bw_t+\bxi_t \rc \leq \min \sumt\lc \mathbf{X}\bw_t+\bxi_t \rc+\frac{\log n}{\eta}+56\eta T.
	\end{equation}
	Finally, combining bounds (\ref{eqn:13}), (\ref{eqn:14}) and dividing by $T$ we have that with probability more than $\frac{1}{2}$,
	\[
	\min \frac{1}{T} \sumt\bp_t^T \lc \mathbf{X}\bw_t+\bxi_t \rc \geq \gamma^*-\frac{2\sqrt{2}}{\sqrt{T}}-\frac{\log n}{\eta T}-80\eta,
	\]
	and using our choices for $T$ and $\eta$, we conclude that with probability at least $\frac{1}{2}$, it holds that
	\[
	\min \lc \mathbf{X}\bw_t+\bxi_t \rc \geq \gamma^* -\varepsilon.
	\]
	This implies that the vectors $(\bar{\bw},\bar{\bxi})$ form an $\varepsilon$-approximate solution.

\end{proof}
\begin{small}
\bibliographystyle{plain}
\bibliography{mlpaper.bib}
\end{small}
\end{document}
