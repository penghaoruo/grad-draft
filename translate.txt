罗吉斯回归模型是一个被广泛应用的有监督学习模型。
本文着眼于大数据背景下，解决针对罗吉斯回归模型优化算法的计算效率问题。
我们的研究主要是在算法层面。
我们研究了三种不同的并行计算系统以及三种不同的计算算法来有效地提升算法的可扩展性。
Hadoop，Mahout以及Spark是当前的三个为人所熟知的并行系统。
它们都能支持大规模机器学习算法在大数据及上的运算。
并行梯度下降和随机梯度下降是两个当前非常经典的优化算法，并且可以专门用于解决罗吉斯回归模型的学习问题。
另外，我们还开发出一种新的并行次线性算法。
该并行算法是建立在线性次线性算法基础上的。
我们会比较这些算法在不同并行系统上的运行结果。
实验结果显示，在不同的数据情况以及不同的系统资源下，我们可以选择有针对性的算法更为高效地解决罗吉斯回归模型的学习问题。
同时，更进一步的研究表明，对于此种需要较长时间执行的分布式并行计算而言，容错能力既可以体现在系统层面，也可以体现在算法层面，我们可以根据解决问题的需要进行平衡。

